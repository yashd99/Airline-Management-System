{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "cols = ['ARTS', 'ARTS & CULTURE', 'BLACK VOICES', 'BUSINESS', 'COLLEGE', 'COMEDY', 'CRIME', 'CULTURE & ARTS', 'DIVORCE', 'EDUCATION', 'ENTERTAINMENT', 'ENVIRONMENT', 'FIFTY', 'FOOD & DRINK', 'GOOD NEWS', 'GREEN', 'HEALTHY LIVING', 'HOME & LIVING', 'IMPACT', 'LATINO VOICES', 'MEDIA', 'MONEY', 'PARENTING', 'PARENTS', 'POLITICS', 'QUEER VOICES', 'RELIGION', 'SCIENCE', 'SPORTS', 'STYLE', 'STYLE & BEAUTY', 'TASTE', 'TECH', 'TRAVEL', 'WEDDINGS', 'WEIRD NEWS', 'WELLNESS', 'WOMEN', 'WORLD NEWS', 'WORLDPOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTraining,BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import re\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "#from fastai.text import Tokenizer, Vocab\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import pdb\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelBinarizer, label_binarize\n",
    "import argparse\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from tqdm.auto import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape (59974, 3)\n",
      "Val Shape (39983, 3)\n",
      "Test Shape (99957, 3)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='BERT Fine-Training')\n",
    "parser.add_argument(\n",
    "    '--fine_tune', '-ft', action='store_true', help='Fine-Tune on dataset')\n",
    "parser.add_argument(\n",
    "    '--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "parser.add_argument(\n",
    "    '--eval', '-e', action='store_true', help='Run eval on checkpoint')\n",
    "parser.add_argument(\n",
    "    '--predict', '-p', action='store_true', help='Run predictions on checkpoint')\n",
    "arg = parser.parse_args()\n",
    "\n",
    "if not os.path.exists('Data'):\n",
    "    os.makedirs('Data')\n",
    "if not os.path.exists('Data/output'):\n",
    "    os.makedirs('Data/output')\n",
    "\n",
    "#Read dataset\n",
    "df3 = pd.read_csv('Data/cleaned.csv')\n",
    "\n",
    "#Splitting data into train, test and val\n",
    "X=df3.sample(frac=0.5,random_state=200)\n",
    "test=df3.drop(X.index)\n",
    "train=X.sample(frac=0.6,random_state=200)\n",
    "val=X.drop(train.index)\n",
    "\n",
    "print(\"Train Shape\", train.shape)\n",
    "print(\"Val Shape\", val.shape)\n",
    "print(\"Test Shape\", test.shape)\n",
    "train.to_csv('Data/train.csv',encoding='utf-8', index=False)\n",
    "val.to_csv('Data/val.csv',encoding='utf-8', index=False)\n",
    "test.to_csv('Data/test.csv',encoding='utf-8', index=False)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=Path('Data/')\n",
    "DATA_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "CLAS_DATA_PATH=DATA_PATH/'output'\n",
    "CLAS_DATA_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "model_state_dict = None\n",
    "#Set this according to your dataset\n",
    "input_col = 2 # 0 based index column input to the model\n",
    "output_col = 1 # 0 based index column label to the model\n",
    "\n",
    "BERT_PRETRAINED_PATH = Path('uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_size\": -1,\n",
    "    \"val_size\": -1,\n",
    "    \"full_data_dir\": DATA_PATH,\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"task_name\": \"news_cat_label\",\n",
    "    \"no_cuda\": False,\n",
    "    \"bert_model\": \"bert-base-uncased\",\n",
    "    \"output_dir\": CLAS_DATA_PATH,\n",
    "    \"max_seq_length\": 50,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 15,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_train_epochs\": 4.0,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": False,\n",
    "    \"loss_scale\": 128\n",
    "}\n",
    "output_model_file = os.path.join(args['output_dir'], \"ckpt.t7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    \"\"\"BERT model for classification.\n",
    "    This module is composed of the BERT model with a linear layer on top of\n",
    "    the pooled output.\n",
    "    Params:\n",
    "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
    "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
    "    Inputs:\n",
    "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
    "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
    "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
    "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
    "            a `sentence B` token (see BERT paper for more details).\n",
    "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
    "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
    "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
    "            a batch has varying length sentences.\n",
    "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
    "            with indices selected in [0, ..., num_labels].\n",
    "    Outputs:\n",
    "        if `labels` is not `None`:\n",
    "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
    "        if `labels` is `None`:\n",
    "            Outputs the classification logits of shape [batch_size, num_labels].\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Already been converted into WordPiece token ids\n",
    "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "    num_labels = 2\n",
    "    model = BertForSequenceClassification(config, num_labels)\n",
    "    logits = model(input_ids, token_type_ids, input_mask)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertForSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            print(param)\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            labels: (Optional) [string]. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "\n",
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class LabelTextProcessor(DataProcessor):\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = None\n",
    "    \n",
    "    \n",
    "    def get_train_examples(self, data_dir, size=-1):\n",
    "        filename = 'train.csv'\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
    "        if size == -1:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename),engine=None)\n",
    "            return self._create_examples(data_df, \"train\")\n",
    "        else:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
    "            return self._create_examples(data_df.sample(size), \"train\")\n",
    "        \n",
    "    def get_dev_examples(self, data_dir, size=-1):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        filename = 'val.csv'\n",
    "        if size == -1:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
    "            return self._create_examples(data_df, \"dev\")\n",
    "        else:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
    "            return self._create_examples(data_df.sample(size), \"dev\")\n",
    "    \n",
    "    def get_test_examples(self,msg, data_dir, data_file_name, size=-1):\n",
    "        \n",
    "        data = [['1', 'ENTERTAINMENT',msg]]\n",
    "        #text2='7 get Covaxin booster shot as study begins on lifelong immunity'\n",
    "        df1 = pd.DataFrame(data, columns = ['Unnamed', 'category','text'])\n",
    "        if size == -1:\n",
    "            return self._create_examples(df1, \"test\")\n",
    "        else:\n",
    "            return self._create_examples(df1.sample(size), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return ['ARTS', 'ARTS & CULTURE', 'BLACK VOICES', 'BUSINESS', 'COLLEGE', 'COMEDY', 'CRIME', 'CULTURE & ARTS', 'DIVORCE', 'EDUCATION', 'ENTERTAINMENT', 'ENVIRONMENT', 'FIFTY', 'FOOD & DRINK', 'GOOD NEWS', 'GREEN', 'HEALTHY LIVING', 'HOME & LIVING', 'IMPACT', 'LATINO VOICES', 'MEDIA', 'MONEY', 'PARENTING', 'PARENTS', 'POLITICS', 'QUEER VOICES', 'RELIGION', 'SCIENCE', 'SPORTS', 'STYLE', 'STYLE & BEAUTY', 'TASTE', 'TECH', 'TRAVEL', 'WEDDINGS', 'WEIRD NEWS', 'WELLNESS', 'WOMEN', 'WORLD NEWS', 'WORLDPOST']\n",
    "        #return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, df, set_type, labels_available=True):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, row) in enumerate(df.values):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = row[input_col]\n",
    "            if labels_available:\n",
    "                labels = row[output_col]\n",
    "                #print('hiiiii',labels)\n",
    "            else:\n",
    "                labels = []\n",
    "                print(\"No Label Found\")\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
    "        return examples\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "    \n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        tokens_b = None\n",
    "        if example.text_b:\n",
    "            tokens_b = tokenizer.tokenize(example.text_b)\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "        else:\n",
    "            # Account for [CLS] and [SEP] with \"- 2\"\n",
    "            if len(tokens_a) > max_seq_length - 2:\n",
    "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens += tokens_b + [\"[SEP]\"]\n",
    "            segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        labels_ids = label_map[example.labels]\n",
    "        if ex_index < 0:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % (example.guid))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(\n",
    "                    [str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_ids=labels_ids))\n",
    "    return features\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:05:28 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/27/2021 10:05:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\jitesh\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    return np.sum(outputs == labels)\n",
    "\n",
    "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
    "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
    "\n",
    "\n",
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean().item()\n",
    "\n",
    "\"\"\"## Training warmup\"\"\"\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x\n",
    "\n",
    "processors = {\n",
    "    \"news_cat_label\": LabelTextProcessor\n",
    "}\n",
    "\n",
    "# Setup GPU parameters\n",
    "\n",
    "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "#     n_gpu = 1\n",
    "else:\n",
    "    torch.cuda.set_device(args['local_rank'])\n",
    "    device = torch.device(\"cuda\", args['local_rank'])\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))\n",
    "\n",
    "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])\n",
    "\n",
    "random.seed(args['seed'])\n",
    "np.random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(args['seed'])\n",
    "\n",
    "task_name = args['task_name'].lower()\n",
    "\n",
    "if task_name not in processors:\n",
    "    raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "\n",
    "processor = processors[task_name](args['data_dir'])\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=args['do_lower_case'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:05:35 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\jitesh\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/27/2021 10:05:35 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file C:\\Users\\jitesh\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\jitesh\\AppData\\Local\\Temp\\tmpbgyu7jgs\n",
      "05/27/2021 10:05:40 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/27/2021 10:05:48 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "05/27/2021 10:05:48 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "    if model_state_dict:\n",
    "        model = BertForSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
    "    else:\n",
    "        model = BertForSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def predict(model, path,msg, test_filename='test1.csv'):\n",
    "    predict_processor = LabelTextProcessor(path)\n",
    "    print(msg)\n",
    "    test_examples = predict_processor.get_test_examples(msg,path, test_filename, size=-1)\n",
    "    \n",
    "    print(test_examples)\n",
    "    # Hold input data for returning it \n",
    "    input_data = [{ 'id': input_example.guid, 'comment_text': input_example.text_a } for input_example in test_examples]\n",
    "\n",
    "    test_features = convert_examples_to_features(\n",
    "        test_examples, label_list, args['max_seq_length'], tokenizer)\n",
    "    print(test_examples)\n",
    "    print(args['max_seq_length'])\n",
    "    \n",
    "    logger.info(\"***** Running prediction *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(test_examples))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "    #print(all_input_mask)\n",
    "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "    \n",
    "    # Run prediction for full data\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
    "    \n",
    "    all_logits = None\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for step, batch in enumerate(tqdm(test_dataloader, desc=\"Prediction Iteration\")):\n",
    "        input_ids, input_mask, segment_ids = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "            logits = F.softmax(logits, -1)\n",
    "            #print(logits)\n",
    "\n",
    "        if all_logits is None:\n",
    "            all_logits = logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "            \n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    return pd.merge(pd.DataFrame(input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(output_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=\"Brazil health regulator rejects Russia's Sputnik vaccine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brazil health regulator rejects Russia's Sputnik vaccine\n",
      "[<__main__.InputExample object at 0x0000028601DAA208>]\n",
      "[<__main__.InputExample object at 0x0000028601DAA208>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2021 15:54:11 - INFO - __main__ -   ***** Running prediction *****\n",
      "04/27/2021 15:54:11 - INFO - __main__ -     Num examples = 1\n",
      "04/27/2021 15:54:11 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f717f5e6df5942408b1bfa3914c2e8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = predict(model, DATA_PATH,msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WORLDPOST'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=result[cols]\n",
    "b=a.idxmax(axis=1, skipna=True)\n",
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTS</th>\n",
       "      <th>ARTS &amp; CULTURE</th>\n",
       "      <th>BLACK VOICES</th>\n",
       "      <th>BUSINESS</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>COMEDY</th>\n",
       "      <th>CRIME</th>\n",
       "      <th>CULTURE &amp; ARTS</th>\n",
       "      <th>DIVORCE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>...</th>\n",
       "      <th>STYLE &amp; BEAUTY</th>\n",
       "      <th>TASTE</th>\n",
       "      <th>TECH</th>\n",
       "      <th>TRAVEL</th>\n",
       "      <th>WEDDINGS</th>\n",
       "      <th>WEIRD NEWS</th>\n",
       "      <th>WELLNESS</th>\n",
       "      <th>WOMEN</th>\n",
       "      <th>WORLD NEWS</th>\n",
       "      <th>WORLDPOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>0.00113</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.699646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARTS  ARTS & CULTURE  BLACK VOICES  BUSINESS   COLLEGE    COMEDY  \\\n",
       "0  0.000636        0.001057      0.000484  0.004217  0.000268  0.001465   \n",
       "\n",
       "      CRIME  CULTURE & ARTS   DIVORCE  EDUCATION  ...  STYLE & BEAUTY  \\\n",
       "0  0.001049        0.000087  0.000561   0.000502  ...         0.00006   \n",
       "\n",
       "      TASTE      TECH    TRAVEL  WEDDINGS  WEIRD NEWS  WELLNESS    WOMEN  \\\n",
       "0  0.001148  0.001574  0.000573  0.000167    0.000726  0.007868  0.00113   \n",
       "\n",
       "   WORLD NEWS  WORLDPOST  \n",
       "0    0.030361   0.699646  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.InputExample at 0x2240baac6c8>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_filename='test1.csv'\n",
    "#data_file_name=test_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msg='7 get Covaxin booster shot as study begins on lifelong immunity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_text():\n",
    "    text3=text2\n",
    "    return text3'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def _create_examples(self, df, set_type, labels_available=True):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, row) in enumerate(df.values):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = row[input_col]\n",
    "            if labels_available:\n",
    "                labels = row[output_col]\n",
    "                #print('hiiiii',labels)\n",
    "            else:\n",
    "                labels = []\n",
    "                print(\"No Label Found\")\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
    "        return examples'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_test_examples(self,msg, data_dir, data_file_name, size=-1):\n",
    "    data = [['1', 'ENTERTAINMENT',msg],['2', 'ENTERTAINMENT',msg]]\n",
    "       \n",
    "    df1 = pd.DataFrame(data, columns = ['Unnamed', 'category','text'])\n",
    "    print(df1)\n",
    "    if size == -1:\n",
    "        return self._create_examples(df1, \"test\")\n",
    "    else:\n",
    "        return self._create_examples(df1.sample(size), \"test\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = pd.read_csv(os.path.join(DATA_PATH, 'test1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text1='hi i am jitesh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.DataFrame(data, columns = ['Unnamed', 'category','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ARTS', 'ARTS & CULTURE', 'BLACK VOICES', 'BUSINESS', 'COLLEGE', 'COMEDY', 'CRIME', 'CULTURE & ARTS', 'DIVORCE', 'EDUCATION', 'ENTERTAINMENT', 'ENVIRONMENT', 'FIFTY', 'FOOD & DRINK', 'GOOD NEWS', 'GREEN', 'HEALTHY LIVING', 'HOME & LIVING', 'IMPACT', 'LATINO VOICES', 'MEDIA', 'MONEY', 'PARENTING', 'PARENTS', 'POLITICS', 'QUEER VOICES', 'RELIGION', 'SCIENCE', 'SPORTS', 'STYLE', 'STYLE & BEAUTY', 'TASTE', 'TECH', 'TRAVEL', 'WEDDINGS', 'WEIRD NEWS', 'WELLNESS', 'WOMEN', 'WORLD NEWS', 'WORLDPOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=result[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_test_examples() missing 3 required positional arguments: 'self', 'data_dir', and 'data_file_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-52ed1efbdc67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_test_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: get_test_examples() missing 3 required positional arguments: 'self', 'data_dir', and 'data_file_name'"
     ]
    }
   ],
   "source": [
    "get_test_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b=a.idxmax(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1133e3acf0a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'message' is not defined"
     ]
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, redirect, url_for, render_template, request, session,jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from werkzeug.wrappers import Request, Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:06:22 - INFO - werkzeug -    * Running on http://localhost:5000/ (Press CTRL+C to quit)\n",
      "05/27/2021 10:06:28 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:06:28] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 10:06:28 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:06:28] \"GET /style.css HTTP/1.1\" 404 -\n",
      "05/27/2021 10:06:29 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:06:29] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "05/27/2021 10:07:37 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:07:37] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 10:07:37 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:07:37] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haryana: 84-yr-old covid patient treated with antibody cocktail, discharged\n",
      "[<__main__.InputExample object at 0x000001F20DDE0E88>]\n",
      "[<__main__.InputExample object at 0x000001F20DDE0E88>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:07:40 - INFO - __main__ -   ***** Running prediction *****\n",
      "05/27/2021 10:07:40 - INFO - __main__ -     Num examples = 1\n",
      "05/27/2021 10:07:40 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05318695842c42408244560af059f83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEALTHY LIVING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:07:42 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:07:42] \"POST /prediction HTTP/1.1\" 200 -\n",
      "05/27/2021 10:08:00 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:08:00] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 10:08:00 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:08:00] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mehul Choksi arrested in Dominica, family says relieved he is safe\n",
      "[<__main__.InputExample object at 0x000001F20DD94688>]\n",
      "[<__main__.InputExample object at 0x000001F20DD94688>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:08:03 - INFO - __main__ -   ***** Running prediction *****\n",
      "05/27/2021 10:08:03 - INFO - __main__ -     Num examples = 1\n",
      "05/27/2021 10:08:03 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8987d6467a3549ad82fdbfe64cd929cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CRIME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:08:03 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:08:03] \"POST /prediction HTTP/1.1\" 200 -\n",
      "05/27/2021 10:08:29 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:08:29] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 10:08:29 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:08:29] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guv nod to Haryana Recovery of Damages to Property Act\n",
      "[<__main__.InputExample object at 0x000001F20DE1D5C8>]\n",
      "[<__main__.InputExample object at 0x000001F20DE1D5C8>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:08:31 - INFO - __main__ -   ***** Running prediction *****\n",
      "05/27/2021 10:08:31 - INFO - __main__ -     Num examples = 1\n",
      "05/27/2021 10:08:31 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3f4881ed1948beb390ca5bbfa41875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORLD NEWS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:08:31 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:08:31] \"POST /prediction HTTP/1.1\" 200 -\n",
      "05/27/2021 10:27:12 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:27:12] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 10:27:12 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:27:12] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At auto driver’s home of hope for elderly in Bengaluru, vaccination is a stumbling block\n",
      "[<__main__.InputExample object at 0x000001F20DE2CC08>]\n",
      "[<__main__.InputExample object at 0x000001F20DE2CC08>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:27:15 - INFO - __main__ -   ***** Running prediction *****\n",
      "05/27/2021 10:27:15 - INFO - __main__ -     Num examples = 1\n",
      "05/27/2021 10:27:15 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa98c6f9467d46a6b63d16897e347be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMPACT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:27:15 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:27:15] \"POST /prediction HTTP/1.1\" 200 -\n",
      "05/27/2021 10:27:38 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:27:38] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 10:27:38 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:27:38] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA Mayor Eric Garcetti is Joe Biden’s choice for India envoy, says report\n",
      "[<__main__.InputExample object at 0x000001F20DE0FF48>]\n",
      "[<__main__.InputExample object at 0x000001F20DE0FF48>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:27:41 - INFO - __main__ -   ***** Running prediction *****\n",
      "05/27/2021 10:27:41 - INFO - __main__ -     Num examples = 1\n",
      "05/27/2021 10:27:41 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f05cb42f2e49d3962cd8a2e6ac5268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POLITICS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:27:41 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:27:41] \"POST /prediction HTTP/1.1\" 200 -\n",
      "05/27/2021 10:56:21 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:56:21] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 10:56:21 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:56:21] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amitabh Bachchan 'Hosts' KBC on Instagram, Asks Fans to Guess His Popular Bollywood Movie\n",
      "[<__main__.InputExample object at 0x000001F20DFED388>]\n",
      "[<__main__.InputExample object at 0x000001F20DFED388>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:56:24 - INFO - __main__ -   ***** Running prediction *****\n",
      "05/27/2021 10:56:24 - INFO - __main__ -     Num examples = 1\n",
      "05/27/2021 10:56:24 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435ec6a49f734d018b9f1d6563522e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENTERTAINMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 10:56:24 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 10:56:24] \"POST /prediction HTTP/1.1\" 200 -\n",
      "05/27/2021 11:40:45 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 11:40:45] \"GET / HTTP/1.1\" 200 -\n",
      "05/27/2021 11:40:45 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 11:40:45] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mehul Choksi arrested in Dominica, family says relieved he is safe\n",
      "[<__main__.InputExample object at 0x000001F20DE1D0C8>]\n",
      "[<__main__.InputExample object at 0x000001F20DE1D0C8>]\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 11:40:48 - INFO - __main__ -   ***** Running prediction *****\n",
      "05/27/2021 11:40:48 - INFO - __main__ -     Num examples = 1\n",
      "05/27/2021 11:40:48 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0077d22ad90d40e9860f5adf55f95a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Prediction Iteration', max=1, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CRIME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2021 11:40:48 - INFO - werkzeug -   127.0.0.1 - - [27/May/2021 11:40:48] \"POST /prediction HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__, template_folder='./')\n",
    "app.static_folder = 'static'\n",
    "\n",
    "@app.route('/prediction', methods=['POST', 'GET'])\n",
    "def prediction():\n",
    "    if request.method == \"POST\":\n",
    "        message = request.form['message']\n",
    "        \n",
    "        \n",
    "        \n",
    "        result = predict(model, DATA_PATH,message)\n",
    "        a=result[cols]\n",
    "        b=a.idxmax(axis=1, skipna=True)\n",
    "        b[0]\n",
    "        response =  b[0]\n",
    "        print(response)\n",
    "        msg=\"The news category is\"\n",
    "        return jsonify(msg,response)\n",
    "    \n",
    "    return jsonify(\"Input text\")\n",
    "\n",
    "@app.route('/')\n",
    "def main():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #app.run(debug=True)\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 5000, app)\n",
    "    \n",
    "@app.route('/shutdown', methods=['POST'])\n",
    "def shutdown():\n",
    "    shutdown_server()\n",
    "    return 'Server shutting down...'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    WORLDPOST\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kejriwal spending crores on publicity but doing nothing to augment oxygen supply in Delhi: Ajay Maken'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
